{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.ndimage import zoom\n",
    "import json\n",
    "import warnings\n",
    "from random import randint\n",
    "import random\n",
    "import SimpleITK as sitk\n",
    "from multi_slice_viewer import multi_slice_viewer\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Conv3D, MaxPooling3D, Dropout, Conv3DTranspose, UpSampling3D, concatenate, Cropping3D, Reshape, BatchNormalization\n",
    "import keras.callbacks\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from IPython.display import clear_output\n",
    "import gzip \n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "#this part is needed if you run the notebook on Cartesius with multiple cores\n",
    "n_cores = 32\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=n_cores-1, inter_op_parallelism_threads=1, allow_soft_placement=True)\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(n_cores-1)\n",
    "os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
    "os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "os.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task03_liver dir in same directory as notebook\n",
    "data_path = './Task03_Liver/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info about dataset in json file\n",
    "with open(data_path + 'dataset.json') as f:\n",
    "    d = json.load(f)   \n",
    "    \n",
    "    # paths to training set images with label\n",
    "    train_paths = d['training']\n",
    "    \n",
    "    # paths to testset images with label\n",
    "    test_paths = d['test'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/home3/hesterh/ISMI_project/Task03_Liver\n"
     ]
    }
   ],
   "source": [
    "# change to data dir \n",
    "os.chdir(data_path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and labels, loading all takes some time\n",
    "train_imgs = [sitk.ReadImage(train_instance['image']) for train_instance in train_paths[0:10]]\n",
    "train_lbls = [sitk.ReadImage(train_instance['label']) for train_instance in train_paths[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train images as numpy\n",
    "np_train_imgs = [sitk.GetArrayFromImage(i) for i in train_imgs]\n",
    "np_train_lbls = [sitk.GetArrayFromImage(i) for i in train_lbls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(np_imgs, spacings):\n",
    "    \"\"\"\n",
    "    Resample to 1mm x 1mm x 1mm. \n",
    "    np_imgs: list of images or labels to be resampled as numpy\n",
    "    spacings: spacings to resample with, order: (z, x, y)\n",
    "    \"\"\" \n",
    "    resampled = []\n",
    "    \n",
    "    for i in range(len(np_imgs)): \n",
    "        # apply zoom with spacing, no clue what spline interpolation is\n",
    "        resampled.append(zoom(np_imgs[i], spacings[i], order=1))\n",
    "\n",
    "    return resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store shapes before to check\n",
    "shapes_before = [img.shape for img in np_train_imgs]\n",
    "\n",
    "# spacings from sitk images\n",
    "spacings = [img.GetSpacing() for img in train_imgs]\n",
    "\n",
    "# change order\n",
    "spacings = [(z, x, y) for x, y, z in spacings]          # order: (z, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/sw/python-3.5.2/lib/python3.5/site-packages/scipy/ndimage/interpolation.py:616: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# resample train images and labels\n",
    "np_train_imgs = resample(np_train_imgs, spacings)\n",
    "np_train_lbls = resample(np_train_lbls, spacings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\t\t\tSpacings\t\tAfter\n",
      "(588, 512, 512)\t\t(1.0, 0.7, 0.7)\t\t(588, 351, 351)\n",
      "(245, 512, 512)\t\t(2.0, 0.8, 0.8)\t\t(490, 386, 386)\n",
      "(94, 512, 512)\t\t(5.0, 0.8, 0.8)\t\t(470, 400, 400)\n",
      "(424, 512, 512)\t\t(1.5, 0.7, 0.7)\t\t(636, 381, 381)\n",
      "(845, 512, 512)\t\t(0.8, 0.9, 0.9)\t\t(676, 472, 472)\n",
      "(513, 512, 512)\t\t(0.8, 0.6, 0.6)\t\t(410, 320, 320)\n",
      "(200, 512, 512)\t\t(1.0, 1.0, 1.0)\t\t(200, 512, 512)\n",
      "(908, 512, 512)\t\t(0.7, 0.8, 0.8)\t\t(636, 404, 404)\n",
      "(856, 512, 512)\t\t(0.8, 0.7, 0.7)\t\t(685, 373, 373)\n",
      "(105, 512, 512)\t\t(4.0, 0.9, 0.9)\t\t(420, 435, 435)\n"
     ]
    }
   ],
   "source": [
    "# lets print what happened.\n",
    "print(\"Before\\t\\t\\tSpacings\\t\\tAfter\")\n",
    "for i in range(len(np_train_imgs)):    \n",
    "    # round for printing\n",
    "    spacing_round = [(round(a, 1), round(b, 1), round(c, 1)) for a, b, c in spacings]    \n",
    "    print(\"{}\\t\\t{}\\t\\t{}\".format(shapes_before[i] , spacing_round[i], np_train_imgs[i].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('liver_data.gz', 'ab') as f:\n",
    "    f.write("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../liver.pickle', 'a+b') as handle:\n",
    "    pickle.dump({'images': np_train_imgs, 'labels': np_train_lbls}, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../liver.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "images = data['images']\n",
    "labels = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
